<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.450">

  <meta name="author" content="Jesse Perla">
  <title>ECON 526 Lectures - ECON526: Quantitative Economics with Data Science Applications</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <style>
  .reveal .custom3070 > div.column:first-child {
    width: 30%;
  }
  .reveal .custom3070 div.column:not(:first-child) {
    width: 70%;
  }
  .reveal .custom4060 > div.column:first-child {
    width: 40%;
  }
  .reveal .custom4060 div.column:not(:first-child) {
    width: 60%;
  }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">ECON526: Quantitative Economics with Data Science Applications</h1>
  <p class="subtitle">Latent Variables and Introduction to Unsupervised Learning</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Jesse Perla 
</div>
<div class="quarto-title-author-email">
<a href="mailto:jesse.perla@ubc.ca">jesse.perla@ubc.ca</a>
</div>
        <p class="quarto-title-affiliation">
            University of British Columbia
          </p>
    </div>
</div>

</section><section id="TOC">
<nav role="doc-toc"> 
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#/overview" id="/toc-overview">Overview</a></li>
<li><a href="#/latent-variables" id="/toc-latent-variables">Latent Variables</a></li>
<li><a href="#/principle-components" id="/toc-principle-components">Principle Components</a></li>
<li><a href="#/auto-encoders" id="/toc-auto-encoders">Auto-Encoders</a></li>
<li><a href="#/discrete-latent-variables" id="/toc-discrete-latent-variables">Discrete Latent Variables</a></li>
<li><a href="#/optional-factors-within-a-portfolio-model" id="/toc-optional-factors-within-a-portfolio-model">(Optional) Factors within a Portfolio Model</a></li>
</ul>
</nav>
</section>
<section>
<section id="overview" class="title-slide slide level1 center">
<h1>Overview</h1>

</section>
<section id="motivation-and-materials" class="slide level2">
<h2>Motivation and Materials</h2>
<ul>
<li>In this lecture, we will continue with some applications of the tools we developed in the previous lectures</li>
<li>We introduce <a href="https://scikit-learn.org/stable/">scikit-learn</a>, a package for old-school (i.e.&nbsp;not deep learning or neural networks) ML and data analysis
<ul>
<li>Introduces “unsupervised learning” (i.e., tools to interpret data structure without any forecasts/predictions)</li>
</ul></li>
</ul>
</section>
<section id="packages" class="slide level2">
<h2>Packages</h2>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> scipy</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">from</span> numpy.linalg <span class="im">import</span> cond, matrix_rank, norm</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">from</span> scipy.linalg <span class="im">import</span> inv, solve, det, eig, lu, eigvals</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">from</span> scipy.linalg <span class="im">import</span> solve_triangular, eigvalsh, cholesky</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section></section>
<section>
<section id="latent-variables" class="title-slide slide level1 center">
<h1>Latent Variables</h1>

</section>
<section id="features-labels-and-latents" class="slide level2">
<h2>Features, Labels, and Latents</h2>
<ul>
<li>Data science and ML often use different terminology than economists:
<ul>
<li><strong>Features</strong> are economists <strong>explanatory or independent variables</strong>. They have the key source of variation to make predictions and conduct counterfactuals</li>
<li><strong>Labels</strong> correspond to economists <strong>observables or dependent variables</strong></li>
<li><strong>Latent Variables</strong> are <strong>unobserved variables</strong>, typically sources of heterogeneity or which may drive both the dependent and independent variables</li>
</ul></li>
<li>Economists will use theory and experience to transform data (i.e., what ML people call “feature engineering”) for better explanatory power or map to theoretical models</li>
</ul>
</section>
<section id="unsupervised-learning" class="slide level2">
<h2>Unsupervised Learning</h2>
<ul>
<li>ML refers to methods using only <strong>features</strong> as <strong>unsupervised learning</strong>. The structure of the underlying data can teach you about its data generating process</li>
<li><strong>Key:</strong> uncover and interpret latent variables using statistics coupled with assumptions from economic theory. There is theory beyond all interpretation</li>
</ul>
</section></section>
<section>
<section id="principle-components" class="title-slide slide level1 center">
<h1>Principle Components</h1>

</section>
<section id="principle-components-and-factor-analysis" class="slide level2">
<h2>Principle Components and Factor Analysis</h2>
<ul>
<li>Another application of eigenvalues is dimension reduction, which simplifies <strong>features</strong> by uncovering <strong>latent</strong> variables. Unsupervised</li>
<li>One technique is Principle Components Analysis (PCA), which uncovers latent variables that capture the primary directions of variation in the underlying data
<ul>
<li>May allow mapping data into a lower-dimensional, uncorrelated features</li>
<li>Uses Singular Value Decomposition (SVD) - a generalization of eigendecomposition to non-square matrices</li>
</ul></li>
<li>Given a matrix <span class="math inline">\(X \in \mathbb{R}^{N \times M}\)</span>, can we find a lower-dimensional representation <span class="math inline">\(Z \in \mathbb{R}^{N \times L}\)</span> for <span class="math inline">\(L &lt; M\)</span> that captures the most variation in <span class="math inline">\(X\)</span>?</li>
<li>The goal is to invert the <span class="math inline">\(X\)</span> data to find the <span class="math inline">\(Z\)</span>—and provide a mapping to reduce the dimensionality for future data.</li>
</ul>
</section>
<section id="singular-value-decomposition" class="slide level2">
<h2>Singular Value Decomposition</h2>
<ul>
<li>Many applications of SVD (e.g., least squares, checking rank), in part because it is especially “numerically stable” (i.e., not sensitive to the roundoff errors we talked about previously)</li>
<li>One application is to find the latent variables in PCA</li>
<li>PCA can be interpreted with an <a href="https://python.quantecon.org/svd_intro.html#application-principal-components-analysis-pca">eigendecomposition</a>, but can be more confusing than just using the SVD directly.</li>
</ul>
</section>
<section id="svd" class="slide level2">
<h2>SVD</h2>
<p>An SVD for any <span class="math inline">\(X \in \mathbb{R}^{N\times M}\)</span> is:</p>
<p><span class="math display">\[
X = U \Sigma V^T
\]</span></p>
<ul>
<li>The diagonal elements of <span class="math inline">\(\Sigma \in \mathbb{R}^{N\times M}\)</span> are singular values, and there are zeros everywhere else. If <span class="math inline">\(M &lt; N\)</span> then there <span class="math inline">\(M\)</span> singular values (<span class="math inline">\(\sigma_1, \ldots \sigma_M\)</span>)
<ul>
<li>Those singular values are also the square roots of the eigenvalues of <span class="math inline">\(X X^T\)</span> (or <span class="math inline">\(X^T X\)</span>)</li>
<li>The number of non-zero singular values is the rank of the matrix <span class="math inline">\(X\)</span></li>
</ul></li>
<li><span class="math inline">\(U\in\mathbb{R}^{N\times N}\)</span> and <span class="math inline">\(V \in \mathbb{R}^{M \times M}\)</span> are orthogonal matrices
<ul>
<li><span class="math inline">\(U\)</span> is eigenvectors of <span class="math inline">\(X X^T\)</span> and <span class="math inline">\(V\)</span> is eigenvectors of <span class="math inline">\(X^T X\)</span></li>
</ul></li>
</ul>
</section>
<section id="decomposing-the-data" class="slide level2">
<h2>Decomposing the Data</h2>
<p>A key result is that we can decompose the data into a sum of outer products of the eigenvectors and singular values. Assume ordered so that <span class="math inline">\(\sigma_1 \geq \sigma_2 \geq \ldots \geq \sigma_M\)</span>: <span class="math display">\[
X = U \Sigma V^T = \sum_{m=1}^M \sigma_m u_m v_m^T
\]</span></p>
<p>Note that</p>
<ul>
<li><span class="math inline">\(u_m \in\mathbb{R}^N\)</span> is the <span class="math inline">\(m\)</span>-th column of <span class="math inline">\(U\)</span> and <span class="math inline">\(v_m \in\mathbb{R}^M\)</span> is the <span class="math inline">\(m\)</span>th column of <span class="math inline">\(V\)</span></li>
<li>So <span class="math inline">\(u_m v_m^T\)</span> is an <span class="math inline">\(N \times M\)</span> matrix but you can show that it is rank-1. i.e., you can decompose it into the product of two vectors.</li>
</ul>
</section>
<section id="interpretation-the-scatter-covariance-matrix" class="slide level2">
<h2>Interpretation the Scatter (Covariance) Matrix</h2>
<ul>
<li>Assuming the data has been de-meaned already, <span class="math inline">\(X^{\top} X\)</span> is the covariance matrix, otherwise it is called a scatter matrix</li>
<li>The covariance matrix, <span class="math inline">\(X^{\top} X\)</span> is a <span class="math inline">\(M \times M\)</span> matrix where <span class="math display">\[
[X^{\top} X]_{ij} = \sum_{k=1}^N x_{ki} x_{kj}
\]</span></li>
<li>Calculates an expression related to the the covariance between features</li>
<li>The eigenvectors of this tell you along which directions is there the most variation</li>
</ul>
</section>
<section id="interpretation-of-the-gram-matrix" class="slide level2">
<h2>Interpretation of the Gram Matrix</h2>
<ul>
<li>The Gramian is <span class="math inline">\(X X^{\top}\)</span> is a <span class="math inline">\(N \times N\)</span> matrix where</li>
</ul>
<p><span class="math display">\[
[X X^{\top}]_{ij} = x_i^{\top} x_j
\]</span></p>
<ul>
<li>i.e., each element measures the similarity between features of the <span class="math inline">\(i\)</span>th and <span class="math inline">\(j\)</span>th observations</li>
<li>Inner products are a classic way to measure similarity
<ul>
<li>If <span class="math inline">\(x_i^T x_j\)</span> is large, then the <span class="math inline">\(i\)</span>th and <span class="math inline">\(j\)</span>th observations are similar, and it is maximized if equal.</li>
<li>If <span class="math inline">\(x_i^T x_j\)</span> is zero then the features are as different as possible</li>
</ul></li>
<li>This is important in what are called ``Kernel methods’’ which form approximations by comparing the similarity of observations</li>
</ul>
</section>
<section id="interpreting-rank" class="slide level2">
<h2>Interpreting Rank</h2>
<ul>
<li>Intuition: rank <span class="math inline">\(r\)</span> if it can be decomposed into the sum of <span class="math inline">\(r\)</span> rank-1 matrices
<ul>
<li>Alternatively, can interpret rank of an <span class="math inline">\(N \times M\)</span> matrix is <span class="math inline">\(3\)</span> if can find a <span class="math inline">\(A \in \mathbb{R}^{N \times 3}\)</span> and <span class="math inline">\(B \in \mathbb{R}^{3 \times M}\)</span> such that <span class="math inline">\(X = A B\)</span></li>
</ul></li>
<li>Remember: this works for <strong>any</strong> matrix <span class="math inline">\(X \in \mathbb{R}^{N \times M}\)</span></li>
</ul>
</section>
<section id="dimension-reduction" class="slide level2">
<h2>Dimension Reduction</h2>
<ul>
<li>Frequently <span class="math inline">\(\sigma_1 \gg \sigma_M\)</span> and the <span class="math inline">\(\sigma_m\)</span> may decay quickly, so we can approximate <span class="math inline">\(X\)</span> with fewer terms by truncating the sum at <span class="math inline">\(L &lt; M\)</span>.</li>
</ul>
<p><span class="math display">\[
X \approx \sum_{m=1}^L \sigma_m u_m v_m^T
\]</span></p>
<ul>
<li>Note that if the data is actually lower-dimensional in a suitable space (e.g., <span class="math inline">\(\text{rank}(X) = L &lt; M\)</span>) then <span class="math inline">\(\sigma_m = 0\)</span> for <span class="math inline">\(L &lt; m \leq M\)</span>, so the truncated sum is exact</li>
</ul>
</section>
<section id="pca-as-an-optimal-dimension-reduction" class="slide level2">
<h2>PCA as an Optimal Dimension Reduction</h2>
<ul>
<li>Can prove that if we truncate at <span class="math inline">\(L &lt; M\)</span>, this is the best rank <span class="math inline">\(L\)</span> approximation to <span class="math inline">\(X\)</span> according to some formal criteria.
<ul>
<li>Intuitively, finds directions of the data that capture the most variation in the covariance matrix</li>
<li>Can prove it is the solution to the optimization problem to explain the most variation in the data with the lowest dimensionality</li>
</ul></li>
</ul>

<aside><div>
<p>See <a href="https://en.wikipedia.org/wiki/Principal_component_analysis#First_component">here</a> for some intuition on this as an optimization problem.</p>
</div></aside></section>
<section id="creating-a-dataset-with-latent-factors" class="slide level2">
<h2>Creating a Dataset with Latent Factors</h2>
<p>Create a dataset with two latent factors, the first dominating</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>N <span class="op">=</span> <span class="dv">50</span> <span class="co"># number of observations</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>L, M <span class="op">=</span> <span class="dv">2</span>, <span class="dv">3</span> <span class="co"># number of latent and observed factors</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>Z <span class="op">=</span> np.random.randn(N, L) <span class="co"># latent factors</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>F <span class="op">=</span> np.array([[<span class="fl">1.0</span>, <span class="fl">0.05</span>], <span class="co"># X_1 = Z_1 + 0.05 Z_2</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>              [<span class="fl">2.0</span>, <span class="fl">0.0</span>], <span class="co"># X_2 = 2 Z_1</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>              [<span class="fl">3.0</span>, <span class="fl">0.1</span>]]) <span class="co"># X_3 = 3 Z_1 + 0.1 Z_2</span></span>
<span id="cb2-7"><a href="#cb2-7"></a>X <span class="op">=</span> Z <span class="op">@</span> F.T <span class="op">+</span> <span class="fl">0.1</span> <span class="op">*</span> np.random.randn(N, M) <span class="co"># added noise</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="bu">print</span>(<span class="ss">f"Z is </span><span class="sc">{</span>Z<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, X is </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Z is (50, 2), X is (50, 3)</code></pre>
</div>
</div>
</section>
<section id="pca-without-dimension-reduction" class="slide level2">
<h2>PCA Without Dimension Reduction</h2>
<ul>
<li>See <a href="https://python.quantecon.org/svd_intro.html">QuantEcon SVD</a> for coding yourself. We will use the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">sklearn</a> package</li>
<li>The explained variance is the fraction of the variance explained by each factor</li>
</ul>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb4-2"><a href="#cb4-2"></a>pca.fit(X)</span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="cf">with</span> np.printoptions(precision<span class="op">=</span><span class="dv">4</span>, suppress<span class="op">=</span><span class="va">True</span>, threshold<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb4-4"><a href="#cb4-4"></a>  <span class="bu">print</span>(<span class="ss">f"Singular Values (sqrt eigenvalues):</span><span class="ch">\n</span><span class="sc">{</span>pca<span class="sc">.</span>singular_values_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-5"><a href="#cb4-5"></a>  <span class="bu">print</span>(<span class="ss">f"Explained Variance (ordered):</span><span class="ch">\n</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Singular Values (sqrt eigenvalues):
[26.0863  0.8233  0.6916]
Explained Variance (ordered):
[0.9983 0.001  0.0007]</code></pre>
</div>
</div>
</section>
<section id="dimension-reduction-with-pca" class="slide level2">
<h2>Dimension Reduction with PCA</h2>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>) <span class="co"># one less, and correctly specified</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>Z_hat <span class="op">=</span> pca.fit_transform(X) <span class="co"># transformed by dropping last factor </span></span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="co"># Scale and sign may not match due to indeterminacy</span></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="bu">print</span>(<span class="ss">f"Correlation of Z_1 to Z_hat_1 = </span><span class="sc">{</span>np<span class="sc">.</span>corrcoef(Z.T, Z_hat.T)[<span class="dv">0</span>,<span class="dv">2</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="bu">print</span>(<span class="ss">f"Correlation of Z_2 to Z_hat_2 = </span><span class="sc">{</span>np<span class="sc">.</span>corrcoef(Z.T, Z_hat.T)[<span class="dv">1</span>,<span class="dv">3</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Correlation of Z_1 to Z_hat_1 = -0.9991910948940889
Correlation of Z_2 to Z_hat_2 = -0.1894085947160488</code></pre>
</div>
</div>
</section>
<section id="interpreting-the-results" class="slide level2">
<h2>Interpreting the Results</h2>
<ul>
<li>The first factor in the decomposition is nearly perfectly (positive or negatively) correlated with the more important latent factor
<ul>
<li>The sign could have gone either way. The key is the shared information</li>
<li>How could you have known the sign is indeterminate?</li>
</ul></li>
<li>The 2nd factor has a good but not great correlation with the 2nd latent. Why?</li>
<li>The variance decomposition that gave a 3rd factor with non-zero variance
<ul>
<li>We only had two latent variables. Why didn’t it figure it out?</li>
</ul></li>
<li>How could you have changed the DGP to make this <strong>less</strong> successful?</li>
</ul>
</section>
<section id="warning" class="slide level2">
<h2>Warning</h2>
<ul>
<li>We have just scratched the surface to build some intuition.</li>
<li>Many missing details and caveats (e.g., you may want to rescale your data, make sure everything is demeaned if implementing yourself, etc.)</li>
<li>Read up on the documentation and theory before using in practice</li>
<li>Many <a href="https://en.wikipedia.org/wiki/Principal_component_analysis#Generalizations">generalizations</a> exist which are more appropriate in particular settings</li>
</ul>
</section></section>
<section>
<section id="auto-encoders" class="title-slide slide level1 center">
<h1>Auto-Encoders</h1>

</section>
<section id="auto-encoders-and-dimensionality-reduction" class="slide level2">
<h2>Auto-Encoders and Dimensionality Reduction</h2>
<ul>
<li>General class of problems which they call auto-encoders in ML/data science
<ul>
<li>Function <span class="math inline">\(f\)</span>, the encoder, maps <span class="math inline">\(X\)</span> to a latent space <span class="math inline">\(Z\)</span>, which may be lower-dimensional</li>
<li>Function <span class="math inline">\(g\)</span>, the decoder, maps points in the latent space <span class="math inline">\(Z\)</span> back to <span class="math inline">\(X\)</span></li>
<li><span class="math inline">\(\theta_e\)</span> and <span class="math inline">\(\theta_d\)</span> are parameters for <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> which we are trying to find</li>
</ul></li>
<li>Then the goal is to find the <span class="math inline">\(\theta_e\)</span> and <span class="math inline">\(\theta_d\)</span> parameters for our encoder, <span class="math inline">\(f\)</span>, and decoder, <span class="math inline">\(g\)</span>, where for as many <span class="math inline">\(X\)</span> as possible we have</li>
</ul>
<p><span class="math display">\[
g(f(x; \theta_e); \theta_d) \approx x
\]</span></p>
<ul>
<li>The <span class="math inline">\(z = f(x;\theta_e)\)</span> may be lower-dimensional, but may be useful regardless</li>
</ul>
</section>
<section id="optimization-problem-for-an-auto-encoder" class="slide level2">
<h2>Optimization Problem for an Auto-encoder</h2>
<ul>
<li><p>If we had a distribution for <span class="math inline">\(x\)</span> then can solve</p>
<p><span class="math display">\[
\min_{\theta_e, \theta_d} \mathbb{E}||g(f(x; \theta_e); \theta_d) - x||_2^2
\]</span></p></li>
<li><p>But typically in practice we replace expectation with empirical distribution <span class="math inline">\(\{x_1,\ldots x_N\}\)</span></p></li>
</ul>
<p><span class="math display">\[
\min_{\theta_e, \theta_d} \frac{1}{N} \sum_{n=1}^N ||g(f(x_n; \theta_e); \theta_d) - x_n||_2^2
\]</span></p>
</section>
<section id="pca-as-a-linear-auto-encoder" class="slide level2">
<h2>PCA as a Linear Auto-Encoder</h2>
<ul>
<li>Let <span class="math inline">\(f(x) = W^T x\)</span> and <span class="math inline">\(g(z) = W z\)</span> where <span class="math inline">\(W \in \mathbb{R}^{M \times L}\)</span>. If <span class="math inline">\(\hat{x} \approx W W^T x\)</span>, “reconstruction error” is <span class="math inline">\(||\hat{x} - x||_2^2\)</span>.</li>
</ul>
<p><span class="math display">\[
\min_{W} \frac{1}{N} \sum_{n=1}^N ||W \overbrace{W^T x_n}^{z_n = f(x_n;W)} - x_n||_2^2,\quad \text{with } W^T W = I
\]</span></p>
<ul>
<li>In more advanced machine learning examples, intuition seems to come up frequently. Related to embeddings, which come up with NLP, networks, etc.</li>
</ul>
</section>
<section id="connection-to-pca" class="slide level2">
<h2>Connection to PCA</h2>
<ul>
<li>From a SVD of <span class="math inline">\(X = U \Sigma V^T\)</span> where <span class="math inline">\(V\)</span> are the eigenvectors. Assuming <span class="math inline">\(\Sigma\)</span> is sorted largest to smallest.
<ul>
<li>If we are using <span class="math inline">\(L\)</span> components, then we truncate by taking the first <span class="math inline">\(L\)</span> columns of <span class="math inline">\(V\)</span> and <span class="math inline">\(\Sigma\)</span></li>
<li>Then let <span class="math inline">\(W^{\top} = \Sigma_{1:L} V_{1:L}^{\top}\)</span></li>
</ul></li>
<li>With this, <span class="math inline">\(f(x) = W^{\top} x\)</span> is an low-dimensional approximation to <span class="math inline">\(x\)</span> that minimizes the reconstruction error</li>
</ul>
</section></section>
<section>
<section id="discrete-latent-variables" class="title-slide slide level1 center">
<h1>Discrete Latent Variables</h1>

</section>
<section id="discrete-latent-variables-1" class="slide level2">
<h2>Discrete Latent Variables</h2>
<ul>
<li>PCA was a way to uncover continuous latent variables or find low-dimensional continuous approximations</li>
<li>But latent variables may be discrete (e.g., types of people, firms)</li>
<li>Hidden discrete variables require assigning observations to groups</li>
</ul>
</section>
<section id="clustering" class="slide level2">
<h2>Clustering</h2>
<ul>
<li>Clustering lets you take a set of observations with (potentially) variables (i.e., features) and try to assign a discrete latent variable to each observation
<ul>
<li>Theory may or may not help us know the number of groups</li>
<li>While some are statistical and probabilistic, most methods assign a single latent type rather than a distribution</li>
<li>Choosing the number of groups to assign to is a challenge that requires theory and regularization - which we will avoid here</li>
<li>Instead, just as with PCA we will choose the number of groups ad-hoc rather than in a disciplined way</li>
</ul></li>
</ul>
</section>
<section id="partitioning-sets" class="slide level2">
<h2>Partitioning Sets</h2>
<ul>
<li>Let <span class="math inline">\(X\in\mathbb{R}^{N\times M}\)</span> with <span class="math inline">\(x_1,\ldots x_N\in\mathbb{R}^M\)</span> the individual observations</li>
<li>Assume that each <span class="math inline">\(x_n\)</span> has a latent discrete <span class="math inline">\(k \in \{1, \ldots K\}\)</span> then we can assign each observation to one group
<ul>
<li><span class="math inline">\(\mathbf{S} \equiv \{S_1, \ldots, S_K\}\)</span> where each <span class="math inline">\(n=1,\ldots N\)</span> is in exactly one <span class="math inline">\(S_k\)</span> (i.e.&nbsp;a partition)</li>
</ul></li>
<li>The goal is to find the partition which is the most likely to assign each <span class="math inline">\(x_n\)</span> the correct latent variable <span class="math inline">\(k\)</span></li>
<li>An alternative interpretation is to think of this as a dimension-reduction technique that reduces complicated data into a low-dimensional discrete variable</li>
<li>In economics, we will sometimes cluster on some observations to reduce the dimension, then leave others continuous</li>
</ul>
</section>
<section id="k-means-clustering" class="slide level2">
<h2>k-means Clustering</h2>
<ul>
<li>Consider if the <span class="math inline">\(n\in S_k\)</span> with should have similar <span class="math inline">\(x_n\)</span>
<ul>
<li>Group observations that are close or similar to each other</li>
<li>As always in linear algebra, close suggests using a norm. The Euclidean norm in the <span class="math inline">\(M\)</span> dimensional feature space is a good baseline</li>
</ul></li>
<li>Objective function of k-means: choose the partition <span class="math inline">\(\mathbf{S}\)</span> which minimizes the norm between observations within each group
<ul>
<li>Normalize by group size <span class="math inline">\(|S_k|\)</span> to avoid distorting the objective function due to different group sizes</li>
</ul></li>
</ul>
</section>
<section id="formal-optimization-problem" class="slide level2">
<h2>Formal Optimization Problem</h2>
<ul>
<li><p>Formally,</p>
<p><span class="math display">\[
\min_{\mathbf{S}} \sum_{k=1}^K \frac{1}{|S_k|}\sum_{x_n, x_{n'} \in S_k} ||x_n - x_{n'}||_2^2
\]</span></p></li>
<li><p>Using standard Euclidean norm between two elements in <span class="math inline">\(S_k\)</span> <span class="math display">\[
||x_n - x_{n'}||_2^2 = \sum_{m=1}^M (x_{nm} - x_{n'm})^2
\]</span></p></li>
</ul>
</section>
<section id="k-means-objective-function" class="slide level2">
<h2>k-means Objective Function</h2>
<ul>
<li><p>Can prove that the previous objective is equivalent to minimizing the sum of the squared distances from the group <span class="math inline">\(k\)</span>’s mean</p>
<p><span class="math display">\[
\min_{\mathbf{S}} \sum_{k=1}^K \sum_{n \in S_k} ||x_n - \bar{x}_k||_2^2
\]</span></p></li>
<li><p>Where the mean of group <span class="math inline">\(k\)</span> is standard, and across all <span class="math inline">\(m\)</span> features</p>
<p><span class="math display">\[
\bar{x}_k \equiv \frac{1}{|S_k|}\sum_{x_n \in S_k} x_n
\]</span></p></li>
<li><p>Avoid different scales so <span class="math inline">\(\bar{x}_k\)</span> isn’t dominated by one feature</p></li>
</ul>
</section>
<section id="generating-data-with-latent-groups" class="slide level2">
<h2>Generating Data with Latent Groups</h2>
<ul>
<li>Generate data with 2 features and 2 latent groups and see how k-means does</li>
<li>First, put the data in a dataframe</li>
</ul>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>mu_1 <span class="op">=</span> np.array([<span class="fl">0.0</span>, <span class="fl">0.0</span>]) <span class="co"># mean of k=1</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>mu_2 <span class="op">=</span> np.array([<span class="fl">1.0</span>, <span class="fl">1.0</span>]) <span class="co"># mean of k=2</span></span>
<span id="cb8-3"><a href="#cb8-3"></a>sigma <span class="op">=</span> np.array([[<span class="fl">0.2</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="fl">0.2</span>]]) <span class="co"># use same variance</span></span>
<span id="cb8-4"><a href="#cb8-4"></a>N <span class="op">=</span> <span class="dv">100</span> <span class="co"># observations</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>X_1 <span class="op">=</span> np.random.multivariate_normal(mu_1, sigma, N)</span>
<span id="cb8-6"><a href="#cb8-6"></a>X_2 <span class="op">=</span> np.random.multivariate_normal(mu_2, sigma, N)</span>
<span id="cb8-7"><a href="#cb8-7"></a>df_1 <span class="op">=</span> pd.DataFrame({<span class="st">"f1"</span>: X_1[:, <span class="dv">0</span>], <span class="st">"f2"</span>: X_1[:, <span class="dv">1</span>], <span class="st">"k"</span>: <span class="dv">1</span>})</span>
<span id="cb8-8"><a href="#cb8-8"></a>df_2 <span class="op">=</span> pd.DataFrame({<span class="st">"f1"</span>: X_2[:, <span class="dv">0</span>], <span class="st">"f2"</span>: X_2[:, <span class="dv">1</span>], <span class="st">"k"</span>: <span class="dv">2</span>})</span>
<span id="cb8-9"><a href="#cb8-9"></a>df <span class="op">=</span> pd.concat([df_1, df_2], ignore_index<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="plotting-code-with-seaborn" class="slide level2">
<h2>Plotting Code with Seaborn</h2>
<div class="cell columns column-output-location" data-execution_count="7">
<div class="column">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb9-2"><a href="#cb9-2"></a>sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">"f1"</span>, y<span class="op">=</span><span class="st">"f2"</span>,</span>
<span id="cb9-3"><a href="#cb9-3"></a>  hue<span class="op">=</span><span class="st">"k"</span>, ax<span class="op">=</span>ax)</span>
<span id="cb9-4"><a href="#cb9-4"></a>ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">"Feature 1"</span>, ylabel<span class="op">=</span><span class="st">"Feature 2"</span>,</span>
<span id="cb9-5"><a href="#cb9-5"></a>  title<span class="op">=</span><span class="st">"Latent Groups"</span>)</span>
<span id="cb9-6"><a href="#cb9-6"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output cell-output-display">
<p><img data-src="latent_variables_files/figure-revealjs/cell-7-output-1.png"></p>
</div>
</div>
</div>
</section>
<section id="k-means-to-recover-the-latent-groups" class="slide level2">
<h2>k-means to Recover the Latent Groups</h2>
<ul>
<li>Run k-means with 2 clusters and check the results</li>
<li>If correlation is close to 1 then successfully recovered the latent groups</li>
<li>If the correlation is close to -1 then it was successful. The latent groups <span class="math inline">\(\hat{k}\)</span> numbers are ordered arbitrarily, just as <span class="math inline">\(k\)</span> was</li>
</ul>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb10-2"><a href="#cb10-2"></a>k_hat <span class="op">=</span> kmeans.fit_predict(df[[<span class="st">"f1"</span>, <span class="st">"f2"</span>]])</span>
<span id="cb10-3"><a href="#cb10-3"></a>df[<span class="st">"k_hat"</span>] <span class="op">=</span> k_hat <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>corr <span class="op">=</span> df[<span class="st">"k"</span>].corr(df[<span class="st">"k_hat"</span>])</span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="bu">print</span>(<span class="ss">f"Correlation between k and k_hat:</span><span class="sc">{</span>corr<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Correlation between k and k_hat:-0.88</code></pre>
</div>
</div>
</section>
<section id="confusion-matrix" class="slide level2">
<h2>Confusion Matrix</h2>
<div class="cell columns column-output-location" data-execution_count="9">
<div class="column">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb12-2"><a href="#cb12-2"></a></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="co"># compute confusion matrix</span></span>
<span id="cb12-4"><a href="#cb12-4"></a>cm <span class="op">=</span> confusion_matrix(df[<span class="st">"k"</span>], df[<span class="st">"k_hat"</span>])</span>
<span id="cb12-5"><a href="#cb12-5"></a></span>
<span id="cb12-6"><a href="#cb12-6"></a><span class="co"># plot confusion matrix</span></span>
<span id="cb12-7"><a href="#cb12-7"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb12-8"><a href="#cb12-8"></a>plt.xlabel(<span class="st">'Predicted k'</span>)</span>
<span id="cb12-9"><a href="#cb12-9"></a>plt.ylabel(<span class="st">'True k'</span>)</span>
<span id="cb12-10"><a href="#cb12-10"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb12-11"><a href="#cb12-11"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output cell-output-display">
<p><img data-src="latent_variables_files/figure-revealjs/cell-9-output-1.png"></p>
</div>
</div>
</div>
</section>
<section id="potentially-swap-hatk-and-compare" class="slide level2">
<h2>Potentially Swap <span class="math inline">\(\hat{k}\)</span> and Compare</h2>
<p>Label ordering arbitary, so “confusion matrix might require reordering to compare</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="cf">if</span> df[<span class="st">'k'</span>].corr(df[<span class="st">'k_hat'</span>]) <span class="op">&lt;</span> <span class="fl">0.5</span>:</span>
<span id="cb13-2"><a href="#cb13-2"></a>  df[<span class="st">'k_hat'</span>] <span class="op">=</span> df[<span class="st">'k_hat'</span>].replace({<span class="dv">1</span>: <span class="dv">2</span>, <span class="dv">2</span>: <span class="dv">1</span>})</span>
<span id="cb13-3"><a href="#cb13-3"></a>  <span class="bu">print</span>(<span class="ss">f"Correlation now </span><span class="sc">{</span>df[<span class="st">'k'</span>]<span class="sc">.</span>corr(df[<span class="st">'k_hat'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-4"><a href="#cb13-4"></a></span>
<span id="cb13-5"><a href="#cb13-5"></a>df[<span class="st">'Cluster'</span>] <span class="op">=</span> df.<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="vs">rf"$k=\hat</span><span class="ch">{{</span><span class="vs">k</span><span class="ch">}}</span><span class="vs">=</span><span class="ch">{{</span><span class="sc">{</span>x[<span class="st">'k'</span>]<span class="sc">:.0g}</span><span class="ch">}}</span><span class="vs">$"</span></span>
<span id="cb13-6"><a href="#cb13-6"></a>                         <span class="cf">if</span> x[<span class="st">'k'</span>] <span class="op">==</span> x[<span class="st">'k_hat'</span>] <span class="cf">else</span> <span class="vs">r'$k \neq \hat</span><span class="sc">{k}</span><span class="vs">$'</span>,</span>
<span id="cb13-7"><a href="#cb13-7"></a>                         axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Correlation now 0.8815882896709472</code></pre>
</div>
</div>
</section>
<section id="plotting-the-uncovered-latent-groups" class="slide level2">
<h2>Plotting the Uncovered Latent Groups</h2>
<div class="cell columns column-output-location" data-execution_count="11">
<div class="column">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb15-2"><a href="#cb15-2"></a>sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">"f1"</span>, y<span class="op">=</span><span class="st">"f2"</span>,</span>
<span id="cb15-3"><a href="#cb15-3"></a>  hue<span class="op">=</span><span class="st">"Cluster"</span>, ax<span class="op">=</span>ax)</span>
<span id="cb15-4"><a href="#cb15-4"></a>ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">"Feature 1"</span>, ylabel<span class="op">=</span><span class="st">"Feature 2"</span>,<span class="op">\</span></span>
<span id="cb15-5"><a href="#cb15-5"></a>       title<span class="op">=</span><span class="st">"k-means Recovered Groups"</span>)</span>
<span id="cb15-6"><a href="#cb15-6"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output cell-output-display">
<p><img data-src="latent_variables_files/figure-revealjs/cell-11-output-1.png"></p>
</div>
</div>
</div>
</section></section>
<section>
<section id="optional-factors-within-a-portfolio-model" class="title-slide slide level1 center">
<h1>(Optional) Factors within a Portfolio Model</h1>

</section>
<section id="simulation" class="slide level2">
<h2>Simulation</h2>
<p>In the previous lecture we introduced code for simulation</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="kw">def</span> simulate(A, X_0, T):</span>
<span id="cb16-2"><a href="#cb16-2"></a>    X <span class="op">=</span> np.zeros((<span class="dv">2</span>, T<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb16-3"><a href="#cb16-3"></a>    X[:,<span class="dv">0</span>] <span class="op">=</span> X_0</span>
<span id="cb16-4"><a href="#cb16-4"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb16-5"><a href="#cb16-5"></a>        X[:,t<span class="op">+</span><span class="dv">1</span>] <span class="op">=</span> A <span class="op">@</span> X[:,t]</span>
<span id="cb16-6"><a href="#cb16-6"></a>    <span class="cf">return</span> X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="a-portfolio-example" class="slide level2">
<h2>A Portfolio Example</h2>
<ul>
<li>Two assets pay dividends <span class="math inline">\(d_t \equiv \begin{bmatrix} d_{1t} &amp; d_{2t} \end{bmatrix}^T\)</span> following <span class="math inline">\(d_{t+1} = A\, d_t\)</span> from <span class="math inline">\(d_0\)</span></li>
<li>Portfolio has <span class="math inline">\(G \equiv \begin{bmatrix} G_1 &amp; G_2 \end{bmatrix}\)</span> shares of each asset and you discount at rate <span class="math inline">\(\beta\)</span></li>
</ul>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>A <span class="op">=</span> np.array([[<span class="fl">0.6619469</span>, <span class="fl">0.49646018</span>],[<span class="fl">0.5840708</span>, <span class="fl">0.4380531</span>]])</span>
<span id="cb17-2"><a href="#cb17-2"></a>G <span class="op">=</span> np.array([[<span class="fl">10.0</span>, <span class="fl">4.0</span>]])       </span>
<span id="cb17-3"><a href="#cb17-3"></a>d_0 <span class="op">=</span> np.array([<span class="fl">1.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb17-4"><a href="#cb17-4"></a>T, beta <span class="op">=</span> <span class="dv">10</span>, <span class="fl">0.9</span></span>
<span id="cb17-5"><a href="#cb17-5"></a>p_0 <span class="op">=</span> G <span class="op">@</span> solve(np.eye(<span class="dv">2</span>) <span class="op">-</span> beta <span class="op">*</span> A, d_0)</span>
<span id="cb17-6"><a href="#cb17-6"></a>d <span class="op">=</span> simulate(A, d_0, T)</span>
<span id="cb17-7"><a href="#cb17-7"></a>y <span class="op">=</span> G <span class="op">@</span> d <span class="co"># total dividends from portfolio</span></span>
<span id="cb17-8"><a href="#cb17-8"></a><span class="bu">print</span>(<span class="ss">f"Portfolio value at t=0 is </span><span class="sc">{</span>p_0[<span class="dv">0</span>]<span class="sc">:.5g}</span><span class="ss">, total dividends at time </span><span class="sc">{</span>T<span class="sc">}</span><span class="ss"> is </span><span class="sc">{</span>y[<span class="dv">0</span>,T]<span class="sc">:.5g}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Portfolio value at t=0 is 1424.5, total dividends at time 10 is 36.955</code></pre>
</div>
</div>
</section>
<section id="dividends-seem-to-grow-at-a-similar-rate" class="slide level2">
<h2>Dividends Seem to Grow at a Similar Rate?</h2>

<img data-src="latent_variables_files/figure-revealjs/cell-14-output-1.png" class="r-stretch"></section>
<section id="digging-deeper" class="slide level2">
<h2>Digging Deeper</h2>
<ul>
<li>Let’s do an eigendecomposition to analyze the factors</li>
</ul>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>Lambda, Q <span class="op">=</span> eig(A)</span>
<span id="cb19-2"><a href="#cb19-2"></a><span class="bu">print</span>(np.real(Lambda))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[ 1.10000000e+00 -2.65486733e-09]</code></pre>
</div>
</div>
<ul>
<li>The first eigenvector is 1.1, but the second is very close to zero!
<ul>
<li>(In fact, I rigged it to be zero by constructing from a <span class="math inline">\(\Lambda\)</span>, so this is all numerical copy/paste errors)</li>
</ul></li>
<li>Suggests that maybe only one latent factor driving both <span class="math inline">\(d_{1t}\)</span> and <span class="math inline">\(d_{2t}\)</span>?</li>
<li>Of course, you may have noticed that the columns in the matrix looked collinear, which was another clue.</li>
</ul>
</section>
<section id="evolution-matrix-is-very-simple-with-lambda_2-0" class="slide level2">
<h2>Evolution Matrix is Very Simple with <span class="math inline">\(\lambda_2 = 0\)</span></h2>
<p>If we stack columns <span class="math inline">\(Q \equiv \begin {bmatrix} q_1 &amp; q_2 \end{bmatrix}\)</span> then, <span class="math display">\[
A = Q \Lambda Q^{-1} = Q \begin{bmatrix} \lambda_1 &amp; 0 \\ 0 &amp; 0 \end{bmatrix} Q^{-1} = \lambda_1 q_1  q_1^{-1}
\]</span></p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>lambda_1 <span class="op">=</span> np.real(Lambda[<span class="dv">0</span>])</span>
<span id="cb21-2"><a href="#cb21-2"></a>q_1 <span class="op">=</span> np.reshape(Q[:,<span class="dv">0</span>], (<span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb21-3"><a href="#cb21-3"></a>q_1_inv <span class="op">=</span> np.reshape(inv(Q)[<span class="dv">0</span>,:], (<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb21-4"><a href="#cb21-4"></a>norm(A <span class="op">-</span> lambda_1 <span class="op">*</span> q_1 <span class="op">@</span> q_1_inv) <span class="co"># pretty close to zero!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>2.663274500543771e-09</code></pre>
</div>
</div>
</section>
<section id="transforming-to-the-latent-state" class="slide level2">
<h2>Transforming to the Latent State</h2>
<ul>
<li>Recall: <span class="math inline">\(A = Q \Lambda Q^{-1}\)</span> can be interpreted as:
<ul>
<li>Transformation to latent space, scaling, transform back</li>
</ul></li>
<li>We can demonstrate this in our example:
<ul>
<li>Transforming <span class="math inline">\(d_0\)</span> to <span class="math inline">\(\ell_0\)</span> using <span class="math inline">\(q_1^{-1}\)</span></li>
<li>Evolving <span class="math inline">\(\ell_t\)</span> from <span class="math inline">\(\ell_0\)</span> with <span class="math inline">\(\ell_{t+1} = \lambda_1 \ell_t\)</span>, or <span class="math inline">\(\ell_t = \lambda_1^t \ell_0\)</span></li>
<li>Transforming back with <span class="math inline">\(q_1\)</span></li>
<li>Checking if it aligns with the <span class="math inline">\(d_t\)</span></li>
</ul></li>
</ul>
</section>
<section id="implementation" class="slide level2">
<h2>Implementation</h2>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>l_0 <span class="op">=</span> lambda_1 <span class="op">*</span> q_1_inv <span class="op">@</span> d_0 <span class="co"># latent space</span></span>
<span id="cb23-2"><a href="#cb23-2"></a>l <span class="op">=</span> l_0 <span class="op">*</span> np.power(lambda_1, np.arange(<span class="dv">0</span>, T)) <span class="co"># powers</span></span>
<span id="cb23-3"><a href="#cb23-3"></a>d_hat <span class="op">=</span> q_1 <span class="op">*</span> l <span class="co"># back to original space</span></span>
<span id="cb23-4"><a href="#cb23-4"></a><span class="co"># Missing d_0 since doing A * d_0 iterations</span></span>
<span id="cb23-5"><a href="#cb23-5"></a><span class="bu">print</span>(<span class="ss">f"norm = </span><span class="sc">{</span>norm(d[:,<span class="dv">1</span>:] <span class="op">-</span> d_hat)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-6"><a href="#cb23-6"></a>y_hat <span class="op">=</span> G <span class="op">@</span> d_hat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>norm = 2.3494410875961204e-10</code></pre>
</div>
</div>
<p>Let’s see if these line up perfectly</p>
</section>
<section id="total-dividends-and-the-latent-variable" class="slide level2">
<h2>Total Dividends and the Latent Variable</h2>


<img data-src="latent_variables_files/figure-revealjs/cell-18-output-1.png" class="r-stretch"><div class="footer footer-default">

</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: false,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,

        height: 720,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>